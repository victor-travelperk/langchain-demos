{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8a6656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llms import get_model\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064c9c14",
   "metadata": {},
   "source": [
    "## TOKENIZATION AND CHUNKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878112b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_files(directory = \"./data\"):\n",
    "    result = []\n",
    "\n",
    "    # Iterate over files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        if os.path.isfile(file_path) and filename.endswith(\".txt\"):\n",
    "            with open(file_path, \"r\") as file:\n",
    "                content = file.read()\n",
    "                result.append(content)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a23c2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_raw = read_text_files()\n",
    "print(f\"There are: {len(documents_raw)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fe22a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Different types of encodings: https://github.com/openai/tiktoken/blob/main/tiktoken/model.py#L14\n",
    "tokenizer = tiktoken.encoding_for_model('text-davinci-003')\n",
    "\n",
    "# Function to count token length\n",
    "def token_len(text) -> int:\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=[]\n",
    "    )\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8004b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Creating the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400, # Size of each individual chunk\n",
    "    chunk_overlap=0, # How much overlap there can be between chunks\n",
    "    length_function=token_len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ba1a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into chunks and make them document\n",
    "documents = text_splitter.create_documents(documents_raw)\n",
    "print(f\"We have {len(documents)} chunks\")\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f405f8",
   "metadata": {},
   "source": [
    "## VECTOR EMBEDDINGS and vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd6f7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "model_name = 'text-embedding-ada-002'\n",
    "embedding_model = OpenAIEmbeddings(model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e972d0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Call embeddings API\n",
    "docsearch = Chroma.from_documents(documents, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c14d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = get_model()\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\", # Chain types: https://python.langchain.com/en/latest/modules/chains/index_examples/question_answering.html\n",
    "    retriever=docsearch.as_retriever(search_kwargs={\"k\": 5}),  # 5 is the max number of results from the retriever\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "query = \"I have a small budget, what hotels can I visit?\"\n",
    "result = qa({\"query\": query})\n",
    "print(result[\"result\"])\n",
    "print(result[\"source_documents\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
